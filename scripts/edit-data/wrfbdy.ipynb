{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "fc77da88",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (2114829407.py, line 1)",
                    "output_type": "error",
                    "traceback": [
                        "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mkfrom netCDF4 import Dataset\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
                    ]
                }
            ],
            "source": "kfrom netCDF4 import Dataset\nfrom glob import glob\nimport numpy as np\nimport sys, os\n\nis_py = os.path.basename(sys.argv[0]) == 'wrfbdy.ju.py'\nRUN_ID = int(sys.argv[1]) if is_py and len(sys.argv) > 1 else 24\n\nroot_dir = '/home/guc/'\ndata_dir = f'runs/{RUN_ID:03}*/'\nroot_data_dir = glob(root_dir + data_dir)[0]\n\nall_files = glob(root_data_dir + 'wrfbdy*')"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "b534b74e",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'Dataset' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mlist_variables\u001b[39m(dataset: \u001b[43mDataset\u001b[49m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    List all variables in the nc dataset for adjustment\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    dataset:    netcdf dataset\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset[x.name].\u001b[34m__dict__\u001b[39m.get(\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dimensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, dataset.variables.values())))\n",
                        "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
                    ]
                }
            ],
            "source": "import matplotlib.pyplot as plt\n\ndef list_variables(dataset: Dataset) -> None:\n    '''\n    List all variables in the nc dataset for adjustment\n    dataset:    netcdf dataset\n    '''\n    print('\\n'.join(map(lambda x: f'{x.name}: {dataset[x.name].__dict__.get('description')} {x.dimensions} {x.shape}', dataset.variables.values())))\n\n# Check the values in the selected wrfbdy file\ndataset = Dataset(all_files[0])\n\n# You can look at the attributes of the file in dictionary\n# format this way. Call dataset.ncattrs if you want all attribute\n# print(dataset.__dict__) \n\n# A function to list all the variables in this file\nlist_variables(dataset)\n\n# print(dataset.variables['U_BXS'][0][0])\n# print(dataset.variables['U_BXS'].dimensions)\n# plt.imshow(dataset.variables['U_BXS'][0][0], cmap='rainbow')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a39b54b",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import math\n\ndef plot_all_vars(dataset: Dataset) -> None:\n    cols_num, len_vars = 10, len(dataset.variables)\n    _, axes = plt.subplots(math.ceil(len_vars / cols_num), cols_num, figsize=(12, 18))\n    idx: int = 0\n    for var in dataset.variables.values():\n        i, j = idx // cols_num, idx % cols_num\n        axes[i][j].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n        axes[i][j].set_title(var.name, x=0.5, y=0.35, fontweight=\"500\", fontsize=6)\n        if j != 0: axes[i][j].set_yticklabels([])\n        if i != 0: axes[i][j].set_xticklabels([])\n        if len(var.shape) == 3: axes[i][j].contourf(var[0], cmap='Spectral')\n        elif len(var.shape) == 4: axes[i][j].contourf(var[0][0], cmap='Spectral')\n        else: continue\n        idx += 1\n\nif not is_py:\n    plot_all_vars(dataset)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2687ad12",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def modify_average_z_layers(src: Dataset, var_names: list[str]) -> Dataset:\n    '''\n    A function to average all variables in each Z-layer\n    src:    A read file pointer to source/input file\n    '''\n    for var_name in var_names:\n        print(f'Processing variable {var_name}...', end='\\r')\n        # Ideally we want to use recursive, but now the size is fixed\n        # so it's fine\n\n        # I can't assign the value directly to out for some reason\n        # so I make a temporary variable\n        modified_out = src.variables[var_name][:]\n        var_shape = src.variables[var_name].shape\n        for time_idx in range(var_shape[0]):\n            for bdy_width_idx in range(var_shape[1]):\n                for bottom_top_idx in range(var_shape[2]):\n                    mean_val_in_z_level = np.mean(src.variables[var_name][time_idx][bdy_width_idx][bottom_top_idx])\n                    modified_out[time_idx][bdy_width_idx][bottom_top_idx][:] = mean_val_in_z_level\n        src.variables[var_name][:] = modified_out\n\n    return src"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3772589c",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def modify_remove_wind(src: Dataset) -> Dataset:\n    '''\n    A function to remove boundary condition wind\n    src:    A read file pointer to source/input file\n    '''\n    for var_name in src.variables.keys():\n        if (var_name.split('_')[0] in ['U', 'V', 'W']):\n            src.variables[var_name][:] = 0.0\n    return src"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "392ca87e",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def modify_reduce_vapor(src: Dataset) -> Dataset:\n    reduction_factor = 0.01\n    for var_name in src.variables.keys():\n        initial = var_name.split('_')[0]\n        if initial == 'QVAPOR':\n            src.variables[var_name][:] *= reduction_factor\n    return src"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f012bd70",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import os\nfile_name: str = 'wrfbdy_d01'\noutput_name: str = root_dir + 'modified-files/' + file_name\n\nif len(glob(output_name)) > 0:\n    os.remove(output_name)\n\n# Three things need to be set: attributes, dimensions, and variables\n# What we want to modify here is the variables\nwith Dataset(all_files[0], 'r', format='NETCDF4') as src:\n    with Dataset(output_name, 'w', format='NETCDF4') as out:\n        # Get the attributes of the original file\n        attributes = src.__dict__\n\n        # Add extra field to attrs, e.g. notes\n        attributes['TITLE'] += ' (MODIFIED)'\n        attributes['NOTE'] = 'Average Top-bottom direction by Mok'\n\n        # Set it into the output\n        out.setncatts(attributes)\n\n        # Copy dimensions\n        for name, dimension in src.dimensions.items():\n            dimension_size = (\n                len(dimension) if not dimension.isunlimited() else None\n            ) # The value should be None for unlimited dimension\n\n            # Create the dimension with its size, make sure to modify it\n            # if you changed the variable dimension\n            out.createDimension(name, dimension_size)\n\n        for name, variable in src.variables.items():\n            out.createVariable(\n                name,\n                variable.datatype,\n                variable.dimensions,\n                zlib = True,            # Lossless compression (optional)\n                complevel = 5,          # Lossless compression (optional)\n                shuffle = True          # Lossless compression (optional)\n            )\n\n            # Set output variable attributes\n            out[name].setncatts(src[name].__dict__)\n            out[name][:] = src[name][:]\n\n        # Modify the variable, see function on the cell above\n        var_names = []\n        for var_name in src.variables.keys():\n            initial = var_name.split('_')[0]\n            if initial in ['PH', 'T', 'QVAPOR']:\n                var_names.append(var_name)\n        out = modify_average_z_layers(out, var_names)\n        out = modify_remove_wind(out)\n        out = modify_reduce_vapor(out)\n\n    print('Done! Congrats \ud83c\udf89')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83d668d6",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import subprocess\n\n# Test reading output file\nif is_py:\n    subprocess.call(['mv', output_name, all_files[0]])\nelse:\n    out_dataset = Dataset(output_name)\n    plot_all_vars(out_dataset)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}